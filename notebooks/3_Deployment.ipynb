{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.metrics import accuracy_score\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.modeling.preprocessing import OneHotEncoder\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.functions import col\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()\n",
    "\n",
    "model_version = yaml.safe_load(open(\"../params.yaml\"))[\"model\"][\"version\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SURVIVED</th>\n",
       "      <th>PCLASS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SIBSP</th>\n",
       "      <th>PARCH</th>\n",
       "      <th>FARE</th>\n",
       "      <th>EMBARKED</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>WHO</th>\n",
       "      <th>ADULT_MALE</th>\n",
       "      <th>DECK</th>\n",
       "      <th>EMBARK_TOWN</th>\n",
       "      <th>ALIVE</th>\n",
       "      <th>ALONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SURVIVED  PCLASS     SEX   AGE  SIBSP  PARCH     FARE EMBARKED   CLASS  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       WHO  ADULT_MALE DECK  EMBARK_TOWN ALIVE  ALONE  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#titanic_df = session.table(\"titanic\")\n",
    "\n",
    "titanic_csv = pd.read_csv('../data/raw/titanic.csv')\n",
    "titanic_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMBARKED\n",
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_csv.EMBARKED.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SEX', 'EMBARKED', 'CLASS', 'WHO', 'DECK', 'EMBARK_TOWN', 'ALIVE']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = titanic_csv.select_dtypes(include=['object']).columns\n",
    "list(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGE': 177, 'DECK': 688, 'EMBARKED': 2, 'EMBARK_TOWN': 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns with null values and their respective counts\n",
    "{\n",
    "    column_name: count_of_null\n",
    "    for column_name, count_of_null in {\n",
    "        col_name: titanic_df.where(col(col_name).is_null()).count()\n",
    "        for col_name in titanic_df.columns\n",
    "    }.items()\n",
    "    if count_of_null > 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\n",
    "    [\"AGE\", \"DECK\", \"ALIVE\", \"ADULT_MALE\", \"EMBARKED\", \"SEX\", \"PCLASS\", \"ALONE\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "|\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"FARE\"   |\n",
      "------------------------------------------------------------------------------\n",
      "|0           |1        |0        |THIRD    |MAN    |SOUTHAMPTON    |7.25     |\n",
      "|1           |1        |0        |FIRST    |WOMAN  |CHERBOURG      |71.2833  |\n",
      "|1           |0        |0        |THIRD    |WOMAN  |SOUTHAMPTON    |7.925    |\n",
      "|1           |1        |0        |FIRST    |WOMAN  |SOUTHAMPTON    |53.1     |\n",
      "|0           |0        |0        |THIRD    |MAN    |SOUTHAMPTON    |8.05     |\n",
      "|0           |0        |0        |THIRD    |MAN    |QUEENSTOWN     |8.4583   |\n",
      "|0           |0        |0        |FIRST    |MAN    |SOUTHAMPTON    |51.8625  |\n",
      "|0           |3        |1        |THIRD    |CHILD  |SOUTHAMPTON    |21.075   |\n",
      "|1           |0        |2        |THIRD    |WOMAN  |SOUTHAMPTON    |11.1333  |\n",
      "|1           |1        |0        |SECOND   |CHILD  |CHERBOURG      |30.0708  |\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df = titanic_df.withColumn(\"FARE\", titanic_df[\"FARE\"].astype(T.FloatType()))\n",
    "\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"CLASS\", \"WHO\", \"EMBARK_TOWN\"]\n",
    "num_cols = [\"SIBSP\", \"PARCH\", \"FARE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "|\"CLASS\"  |\"WHO\"  |\"EMBARK_TOWN\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\n",
      "------------------------------------------------------------------------------\n",
      "|THIRD    |MAN    |SOUTHAMPTON    |0           |1        |0        |7.25     |\n",
      "|FIRST    |WOMAN  |CHERBOURG      |1           |1        |0        |71.2833  |\n",
      "|THIRD    |WOMAN  |SOUTHAMPTON    |1           |0        |0        |7.925    |\n",
      "|FIRST    |WOMAN  |SOUTHAMPTON    |1           |1        |0        |53.1     |\n",
      "|THIRD    |MAN    |SOUTHAMPTON    |0           |0        |0        |8.05     |\n",
      "|THIRD    |MAN    |QUEENSTOWN     |0           |0        |0        |8.4583   |\n",
      "|FIRST    |MAN    |SOUTHAMPTON    |0           |0        |0        |51.8625  |\n",
      "|THIRD    |CHILD  |SOUTHAMPTON    |0           |3        |1        |21.075   |\n",
      "|THIRD    |WOMAN  |SOUTHAMPTON    |1           |0        |2        |11.1333  |\n",
      "|SECOND   |CHILD  |CHERBOURG      |1           |1        |0        |30.0708  |\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impute_cat = SimpleImputer(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    strategy=\"most_frequent\",\n",
    "    drop_input_cols=True,\n",
    ")\n",
    "\n",
    "titanic_df = impute_cat.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/imputer.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(impute_cat, file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/snowflake_ml_py311/lib/python3.11/site-packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:853: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/opt/anaconda3/envs/snowflake_ml_py311/lib/python3.11/site-packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:854: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/opt/anaconda3/envs/snowflake_ml_py311/lib/python3.11/site-packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:853: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_CATEGORY]] = state_pandas[[_CATEGORY]].applymap(convert_to_string_excluding_nan)\n",
      "/opt/anaconda3/envs/snowflake_ml_py311/lib/python3.11/site-packages/snowflake/ml/modeling/preprocessing/one_hot_encoder.py:854: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  state_pandas[[_FITTED_CATEGORY]] = state_pandas[[_FITTED_CATEGORY]].applymap(convert_to_string_excluding_nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CLASS_SECOND\"  |\"CLASS_THIRD\"  |\"WHO_MAN\"  |\"WHO_WOMAN\"  |\"EMBARK_TOWN_QUEENSTOWN\"  |\"EMBARK_TOWN_SOUTHAMPTON\"  |\"SURVIVED\"  |\"SIBSP\"  |\"PARCH\"  |\"FARE\"   |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |1        |0        |7.25     |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |0.0                        |1           |1        |0        |71.2833  |\n",
      "|0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |0        |7.925    |\n",
      "|0.0             |0.0            |0.0        |1.0          |0.0                       |1.0                        |1           |1        |0        |53.1     |\n",
      "|0.0             |1.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |8.05     |\n",
      "|0.0             |1.0            |1.0        |0.0          |1.0                       |0.0                        |0           |0        |0        |8.4583   |\n",
      "|0.0             |0.0            |1.0        |0.0          |0.0                       |1.0                        |0           |0        |0        |51.8625  |\n",
      "|0.0             |1.0            |0.0        |0.0          |0.0                       |1.0                        |0           |3        |1        |21.075   |\n",
      "|0.0             |1.0            |0.0        |1.0          |0.0                       |1.0                        |1           |0        |2        |11.1333  |\n",
      "|1.0             |0.0            |0.0        |0.0          |0.0                       |0.0                        |1           |1        |0        |30.0708  |\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OHE = OneHotEncoder(\n",
    "    input_cols=cat_cols,\n",
    "    output_cols=cat_cols,\n",
    "    drop_input_cols=True,\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    ")\n",
    "\n",
    "titanic_df = OHE.fit(titanic_df).transform(titanic_df)\n",
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/onehotencoder.pkl', 'wb') as file: \n",
    "      \n",
    "    # A new file will be created \n",
    "    pickle.dump(OHE, file) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir)) + '/data'\n",
    "titanic_pd = pd.DataFrame(titanic_df.collect())\n",
    "cleaned_dir = os.makedirs(data_dir + \"/training\", exist_ok=True)\n",
    "titanic_pd.to_csv(\"../data/training/titanic.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = titanic_df.random_split(weights=[0.8, 0.2], seed=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"learning_rate\": [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"max_depth\": list(range(3, 6, 1)),\n",
    "    \"min_child_weight\": list(range(1, 6, 1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=LARGE;\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientists may not have the ability to change the warehouse size.  They will usually have access to a larger warehouse and can easily switch as well using session.use_warehouse('bigger_warehouse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid=parameters,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    input_cols=train_df.drop(\"SURVIVED\").columns,\n",
    "    label_cols=\"SURVIVED\",\n",
    "    output_cols=\"PRED_SURVIVED\",\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\n",
    "    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} SET WAREHOUSE_SIZE=XSMALL;\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = grid_search.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(\n",
    "    df=result, y_true_col_names=\"SURVIVED\", y_pred_col_names=\"PRED_SURVIVED\"\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each combination of hyperparameters with their accuracy\n",
    "results = grid_search.to_sklearn().cv_results_\n",
    "data = {\"accuracy\": results[\"mean_test_score\"]}\n",
    "for i, param in enumerate(results[\"params\"]):\n",
    "    for key, value in param.items():\n",
    "        if key not in data:\n",
    "            data[key] = [None] * len(results[\"params\"])\n",
    "        data[key][i] = value\n",
    "\n",
    "# Create DataFrame\n",
    "hp_df = pd.DataFrame(data).sort_values(by=\"accuracy\", ascending=False)\n",
    "hp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = grid_search.to_sklearn().best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to add one to our model versions if it already exists\n",
    "\n",
    "\n",
    "def check_and_update(df, model_name):\n",
    "    if df.empty:\n",
    "        return \"V_1\"\n",
    "    elif df[df[\"name\"] == model_name].empty:\n",
    "        return \"V_1\"\n",
    "    else:\n",
    "        # Increment model_version if df is not a pandas Series\n",
    "        lst = sorted(ast.literal_eval(df[\"versions\"][0]))\n",
    "        last_value = lst[-1]\n",
    "        prefix, num = last_value.rsplit(\"_\", 1)\n",
    "        new_last_value = f\"{prefix}_{int(num)+1}\"\n",
    "        lst[-1] = new_last_value\n",
    "        return new_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Registry Object\n",
    "reg = Registry\n",
    "\n",
    "# Get sample input data to pass into the registry logging function\n",
    "X = train_df.drop(\"SURVIVED\").limit(100)\n",
    "\n",
    "\n",
    "# Define model name and version (use uppercase for name)\n",
    "\n",
    "titanic_model = reg.log_model(\n",
    "    model_name=\"TITANIC\",\n",
    "    version_name=model_version,\n",
    "    model=optimal_model,\n",
    "    sample_input_data=X,\n",
    ")\n",
    "\n",
    "# Add evaluation metric\n",
    "titanic_model.set_metric(\n",
    "    metric_name=\"accuracy\",\n",
    "    value=hp_df[\"accuracy\"][0],\n",
    ")\n",
    "\n",
    "session.file.put(\"../models/imputer.pkl\", \"@ml_data/models_\" + model_version, overwrite=True)\n",
    "session.file.put(\"../models/onehotencoder.pkl\", \"@ml_data/models_\" + model_version, overwrite=True)\n",
    "session.file.put(\"../data/training/titanic.csv\", \"@ml_data/data_\" + model_version + \"/training\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    k: v for k, v in optimal_model.get_params().items() if v and k != \"missing\"\n",
    "}\n",
    "titanic_model.set_metric(metric_name=\"hyperparameters\", value=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500\n",
    "reg.get_model(model_name).show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have multiple versions of the model, we want the UDF to be deployed as the version with the highest accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = reg.get_model(model_name).show_versions()\n",
    "reg_df[\"accuracy\"] = reg_df[\"metadata\"].apply(\n",
    "    lambda x: json.loads(x)[\"metrics\"][\"accuracy\"]\n",
    ")\n",
    "best_model = reg_df.sort_values(by=\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_version = best_model[\"name\"].iloc[0]\n",
    "deployed_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the default version to the deployed version (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = reg.get_model(model_name)\n",
    "m.default = deployed_version\n",
    "mv = m.default\n",
    "mv.version_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
    "remote_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test in SQL write test data back to a table\n",
    "\n",
    "test_df.write.mode(\"overwrite\").save_as_table(\"TEST_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add images to stage for Streamlit App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\"../streamlit_images/*\", \"@ML_DATA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling Model from SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy this code in a snowflake worksheet or run via session.sql\n",
    "inference_df = session.sql('''\n",
    "select *, TITANIC!predict_proba(*):output_feature_0\n",
    "as surv_pred\n",
    "from (\n",
    "select * exclude survived\n",
    "from test_data)\n",
    "            ''')\n",
    "inference_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling model from a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to the registry\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "# Get the default version of your model (Model with best accuracy in our case)\n",
    "\n",
    "mv = reg.get_model(\"titanic\").default\n",
    "\n",
    "remote_prediction = mv.run(test_df, function_name=\"predict_proba\")\n",
    "remote_prediction.drop('\"output_feature_0\"').with_column_renamed(\n",
    "    '\"output_feature_1\"', \"pred_survived\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To delete your model and all of it's versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg.delete_model(\"TITANIC\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro_SnowML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
